{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cftime\n",
    "import dask\n",
    "import xarrayutils\n",
    "import cartopy.crs as ccrs\n",
    "from xmip.preprocessing import combined_preprocessing\n",
    "from xmip.preprocessing import replace_x_y_nominal_lat_lon\n",
    "from xmip.drift_removal import replace_time\n",
    "from xmip.postprocessing import concat_experiments\n",
    "import xmip.drift_removal as xm_dr\n",
    "import xmip as xm\n",
    "import xesmf as xe\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import utils\n",
    "import cf_xarray as cfxr\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.signal as signal\n",
    "from scipy import stats\n",
    "from datetime import timedelta\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import cmocean\n",
    "import cmocean.cm as cmo\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7f161c18dc70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(**{'array.slicing.split_large_chunks': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ds = xr.open_dataset('Outputs/G_ds.nc4')['__xarray_dataarray_variable__']\n",
    "\n",
    "G_CDR_ds = xr.open_dataset('Outputs/G_cdr_ds.nc4')['__xarray_dataarray_variable__']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rolling 5 year mean \n",
    "G_ds = G_ds.rolling(year = 5, min_periods = 1, center = False).mean('year')\n",
    "G_CDR_ds = G_CDR_ds.rolling(year = 5, min_periods = 1, center = False).mean('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ds = xr.concat([G_ds, -G_CDR_ds], pd.Index(['pulse','cdr'], name = 'pulse_type'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ds.name = 'G[tas]'\n",
    "G_ds = G_ds.rename({'year':'s'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "GFDL: 1pct and esm pi-control start from year 0001\n",
    "\n",
    "UKESM1: 1pct starts in 1850 and pi-control starts in 1960, move 1pct to start in 1960\n",
    "\n",
    "MIROC: both start from 1850\n",
    "\n",
    "NORESM2: 1pct from 0001 pi-control from 1600-- move 1pct to 1600\n",
    "\n",
    "ACCESS: 1pct and pi-control from 0101\n",
    "\n",
    "CANESM5_r1p2: 1pct 1850, pi-control 5550, move 1pct to 5550\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run_pulse_dict = utils.model_run_pulse_dict\n",
    "model_run_1pct_dict = utils.model_run_1pct_dict\n",
    "model_run_control_dict = utils.model_run_picontrol_dict\n",
    "model_run_cdr_pulse_dict = utils.model_run_cdr_pulse_dict\n",
    "model_run_1pct1000gtc_dict = utils.model_run_1pct_1000gtc_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_color = utils.model_color\n",
    "type_color = utils.type_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = utils.A\n",
    "ds_out = utils.ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKESM1_r1\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKESM1_r2\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKESM1_r3\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKESM1_r4\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIROC\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORESM2\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFDL\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANESM5_r1p2\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANESM5_r2p2\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANESM5_r3p2\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANESM5_r1p1\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANESM5_r2p1\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANESM5_r3p1\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKESM1_r1\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKESM1_r2\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKESM1_r3\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKESM1_r4\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIROC\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORESM2\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANESM5_r1p2\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANESM5_r2p2\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANESM5_r3p2\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    }
   ],
   "source": [
    "tas_co2_1pct1000gtc = {}\n",
    "tas_co2_pictrl = {}\n",
    "tas_1pct = {}\n",
    "\n",
    "for m in model_run_1pct_dict.keys():\n",
    "    print(m)\n",
    "    print('tas')\n",
    "    tas_1pct[m] = xr.open_mfdataset(f'cmip6_data/tas_Amon_{model_run_1pct_dict[m]}',  use_cftime=True) #kg/m2/s\n",
    "    lat_corners = cfxr.bounds_to_vertices(tas_1pct[m].isel(time = 0)['lat_bnds'], \"bnds\", order=None)\n",
    "    lon_corners = cfxr.bounds_to_vertices(tas_1pct[m].isel(time = 0)['lon_bnds'], \"bnds\", order=None)\n",
    "    tas_1pct[m] = tas_1pct[m].assign(lon_b=lon_corners, lat_b=lat_corners)\n",
    "    tas_1pct[m] = utils._regrid_ds(tas_1pct[m], ds_out)\n",
    "    \n",
    "    \n",
    "for m in model_run_1pct1000gtc_dict.keys():\n",
    "    print(m)\n",
    "    print('tas')\n",
    "    tas_co2_1pct1000gtc[m] = xr.open_mfdataset(f'cmip6_data/tas_Amon_{model_run_1pct1000gtc_dict[m]}',  use_cftime=True) #kg/m2/s\n",
    "    lat_corners = cfxr.bounds_to_vertices(tas_co2_1pct1000gtc[m].isel(time = 0)['lat_bnds'], \"bnds\", order=None)\n",
    "    lon_corners = cfxr.bounds_to_vertices(tas_co2_1pct1000gtc[m].isel(time = 0)['lon_bnds'], \"bnds\", order=None)\n",
    "    tas_co2_1pct1000gtc[m] = tas_co2_1pct1000gtc[m].assign(lon_b=lon_corners, lat_b=lat_corners)\n",
    "    tas_co2_1pct1000gtc[m] = utils._regrid_ds(tas_co2_1pct1000gtc[m], ds_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in tas_co2_1pct1000gtc.keys():\n",
    "    tas_co2_1pct1000gtc[m] = xr.concat([tas_1pct[m].loc[dict(time = slice(tas_1pct[m]['time'].min(), tas_co2_1pct1000gtc[m]['time'].min()-timedelta(30)))] , \n",
    "                                        tas_co2_1pct1000gtc[m]],\n",
    "                 dim = 'time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKESM1_r1\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIROC\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORESM2\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFDL\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANESM5_r1p2\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANESM5_r1p1\n",
      "tas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    }
   ],
   "source": [
    "for m in model_run_control_dict.keys():\n",
    "    print(m)\n",
    "    print('tas')\n",
    "    tas_co2_pictrl[m] = xr.open_mfdataset(f'cmip6_data/tas_Amon_{model_run_control_dict[m]}',  use_cftime=True) #kg/m2/s\n",
    "    lat_corners = cfxr.bounds_to_vertices(tas_co2_pictrl[m].isel(time = 0)['lat_bnds'], \"bnds\", order=None)\n",
    "    lon_corners = cfxr.bounds_to_vertices(tas_co2_pictrl[m].isel(time = 0)['lon_bnds'], \"bnds\", order=None)\n",
    "    tas_co2_pictrl[m] = tas_co2_pictrl[m].assign(lon_b=lon_corners, lat_b=lat_corners)\n",
    "    tas_co2_pictrl[m] = utils._regrid_ds(tas_co2_pictrl[m], ds_out)\n",
    "\n",
    "## fix the times so that they line up according to the notes above\n",
    "m = 'NORESM2'\n",
    "tas_co2_pictrl[m]['time'] = tas_co2_pictrl[m]['time'] -timedelta(365*1599)\n",
    "\n",
    "m = 'UKESM1_r1'\n",
    "tas_co2_pictrl[m]['time'] = tas_co2_pictrl[m]['time'] - timedelta(360*110)\n",
    "\n",
    "m = 'CANESM5_r1p2'\n",
    "tas_co2_pictrl[m]['time'] = tas_co2_pictrl[m]['time']- timedelta(365*3700)\n",
    "\n",
    "m = 'CANESM5_r1p1'\n",
    "tas_co2_pictrl[m]['time'] = tas_co2_pictrl[m]['time']- timedelta(365*3351)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKESM1_r1\n",
      "UKESM1_r1 UKESM1_r1\n",
      "UKESM1_r2\n",
      "UKESM1_r2 UKESM1_r1\n",
      "UKESM1_r3\n",
      "UKESM1_r3 UKESM1_r1\n",
      "UKESM1_r4\n",
      "UKESM1_r4 UKESM1_r1\n",
      "MIROC\n",
      "MIROC MIROC\n",
      "NORESM2\n",
      "NORESM2 NORESM2\n",
      "ACCESS\n",
      "ACCESS ACCESS\n",
      "CANESM5_r1p2\n",
      "CANESM5_r1p2 CANESM5_r1p2\n",
      "CANESM5_r2p2\n",
      "CANESM5_r2p2 CANESM5_r1p2\n",
      "CANESM5_r3p2\n",
      "CANESM5_r3p2 CANESM5_r1p2\n"
     ]
    }
   ],
   "source": [
    "dif_1000gtc = {}\n",
    "for m1 in model_run_1pct1000gtc_dict.keys():\n",
    "    print(m1)\n",
    "    if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "        m2 = 'UKESM1_r1'\n",
    "    elif m1 == 'CANESM5_r1p2' or m1 == 'CANESM5_r2p2' or m1 == 'CANESM5_r3p2' or m1 == 'CANESM5_r4p2' or m1 == 'CANESM5_r5p2':\n",
    "         m2 = 'CANESM5_r1p2'\n",
    "    else:\n",
    "        m2 = m1\n",
    "    print(m1, m2)\n",
    "    \n",
    "    dif_1000gtc[m1] = tas_co2_1pct1000gtc[m1] - tas_co2_pictrl[m2]\n",
    "    \n",
    "    if len(dif_1000gtc[m1]['time']) > 3000:  #hack to get the time stamping to work, should find better fix\n",
    "        periods = 3000\n",
    "    else:\n",
    "        periods = len(dif_1000gtc[m1]['time'])\n",
    "        \n",
    "    times = pd.date_range('2000', periods= periods, freq='MS')\n",
    "    weights = times.shift(1, 'MS') - times\n",
    "    weights = xr.DataArray(weights, [('time', dif_1000gtc[m1]['time'][:periods].values)]).astype('float')\n",
    "    dif_1000gtc[m1] =  (dif_1000gtc[m1] * weights).groupby('time.year').sum('time')/weights.groupby('time.year').sum('time')\n",
    "\n",
    "    dif_1000gtc[m1]['year'] = range(len(dif_1000gtc[m1]['year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKESM1_r1 UKESM1_r1\n",
      "UKESM1_r2 UKESM1_r1\n",
      "UKESM1_r3 UKESM1_r1\n",
      "UKESM1_r4 UKESM1_r1\n",
      "MIROC MIROC\n",
      "NORESM2 NORESM2\n",
      "ACCESS ACCESS\n",
      "GFDL GFDL\n",
      "CANESM5_r1p2 CANESM5_r1p2\n",
      "CANESM5_r2p2 CANESM5_r1p2\n",
      "CANESM5_r3p2 CANESM5_r1p2\n",
      "CANESM5_r1p1 CANESM5_r1p1\n",
      "CANESM5_r2p1 CANESM5_r1p1\n",
      "CANESM5_r3p1 CANESM5_r1p1\n"
     ]
    }
   ],
   "source": [
    "dif_1pct = {}\n",
    "for m1 in model_run_1pct_dict.keys():\n",
    "    if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "        m2 = 'UKESM1_r1'\n",
    "    elif m1 == 'CANESM5_r1p1' or m1 == 'CANESM5_r2p1' or m1 == 'CANESM5_r3p1':\n",
    "         m2 = 'CANESM5_r1p1'\n",
    "    elif m1 == 'CANESM5_r1p2' or m1 == 'CANESM5_r2p2' or m1 == 'CANESM5_r3p2':\n",
    "         m2 = 'CANESM5_r1p2'\n",
    "    else:\n",
    "        m2 = m1\n",
    "    print(m1, m2)\n",
    "    \n",
    "    \n",
    "    dif_1pct[m1] = tas_1pct[m1] - tas_co2_pictrl[m2]\n",
    "    \n",
    "    if len(dif_1pct[m1]['time']) > 3000:  #hack to get the time stamping to work, should find better fix\n",
    "        periods = 3000\n",
    "    else:\n",
    "        periods = len(dif_1pct[m1]['time'])\n",
    "        \n",
    "    times = pd.date_range('2000', periods= periods, freq='MS')\n",
    "    weights = times.shift(1, 'MS') - times\n",
    "    weights = xr.DataArray(weights, [('time', dif_1pct[m1]['time'][:periods].values)]).astype('float')\n",
    "    dif_1pct[m1] =  (dif_1pct[m1] * weights).groupby('time.year').sum('time')/weights.groupby('time.year').sum('time')\n",
    "\n",
    "    dif_1pct[m1]['year'] = range(len(dif_1pct[m1]['year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in dif_1pct.keys():\n",
    "    dif_1pct[m] = dif_1pct[m].drop('height')\n",
    "for m in dif_1000gtc.keys():\n",
    "    dif_1000gtc[m] = dif_1000gtc[m].drop('height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of height and limit the time to the length of the GF\n",
    "for m1 in ['UKESM1_r1', 'UKESM1_r2', 'UKESM1_r3', 'UKESM1_r4', 'NORESM2',\n",
    "       'GFDL', 'MIROC', 'CANESM5_r1p2', 'CANESM5_r2p2', 'ACCESS', 'CANESM5_r3p2']:\n",
    "    \n",
    "    for t in ['pulse','cdr']:\n",
    "        if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "            m2 = 'UKESM1_r1'\n",
    "        elif m1 == 'CANESM5_r1p1' or m1 == 'CANESM5_r2p1' or m1 == 'CANESM5_r3p1':\n",
    "             m2 = 'CANESM5_r1p1'\n",
    "        elif m1 == 'CANESM5_r1p2' or m1 == 'CANESM5_r2p2' or m1 == 'CANESM5_r3p2':\n",
    "             m2 = 'CANESM5_r1p2'\n",
    "        else:\n",
    "            m2 = m1\n",
    "    \n",
    "        \n",
    "        length = len(G_ds.sel(model = m2, pulse_type = t).dropna(dim = 's')['s'])\n",
    "        dif_1pct[m] = dif_1pct[m].sel(year = slice(0,length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m1 in ['UKESM1_r1', 'UKESM1_r2', 'UKESM1_r3', 'UKESM1_r4', 'NORESM2',\n",
    "       'GFDL', 'MIROC', 'CANESM5_r1p2', 'CANESM5_r2p2', 'ACCESS', 'CANESM5_r3p2']:\n",
    "    \n",
    "    for t in ['pulse','cdr']:\n",
    "        if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "            m2 = 'UKESM1_r1'\n",
    "        elif m1 == 'CANESM5_r1p2' or m1 == 'CANESM5_r2p2' or m1 == 'CANESM5_r3p2' or m1 == 'CANESM5_r4p2' or m1 == 'CANESM5_r5p2':\n",
    "             m2 = 'CANESM5_r1p2'\n",
    "        else:\n",
    "            m2 = m1    \n",
    "        \n",
    "        length = len(G_ds.sel(model = m2, pulse_type = t).dropna(dim = 's')['s'])\n",
    "        dif_1000gtc[m] = dif_1000gtc[m].sel(year = slice(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dif_1pct = xr.concat([dif_1pct[m] for m in dif_1pct.keys()], pd.Index([m for m in dif_1pct.keys()], name='model'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dif_1000gtc = xr.concat([dif_1000gtc[m] for m in dif_1000gtc.keys()], pd.Index([m for m in dif_1000gtc.keys()], name='model'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/dask/array/core.py:4697: PerformanceWarning: Increasing number of chunks by factor of 10\n",
      "  result = blockwise(\n",
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/dask/array/core.py:4697: PerformanceWarning: Increasing number of chunks by factor of 14\n",
      "  result = blockwise(\n"
     ]
    }
   ],
   "source": [
    "ds_dif = xr.concat([ds_dif_1000gtc, ds_dif_1pct], pd.Index(['1000gtc','1pct'], name='experiment'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dif = ds_dif.rename({'year':'s'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emissions profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emis_profile_1pct = xr.open_dataset(f'Outputs/1pct_emis_profile_full.nc4')\n",
    "emis_profile_1pct = emis_profile_1pct.rename({'__xarray_dataarray_variable__':'emis'})\n",
    "\n",
    "emis_profile_1000gtc =  xr.open_dataset(f'Outputs/1pct1000gtc_emis_profile_full.nc4')\n",
    "emis_profile_1000gtc = emis_profile_1000gtc.rename({'__xarray_dataarray_variable__':'emis'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "emis_profile = xr.concat([emis_profile_1000gtc, emis_profile_1pct], pd.Index(['1000gtc','1pct'], name='experiment'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our weights for models (grouping UKESM and CANESM realizations)\n",
    "model_weights = {'UKESM1_r1': 0.25, 'UKESM1_r2': 0.25, 'UKESM1_r3': 0.25, 'UKESM1_r4': 0.25, 'NORESM2': 1, 'GFDL': 1,\n",
    "       'MIROC': 1, 'ACCESS': 1,  'CANESM5_r2p2':1/3, 'CANESM5_r1p2':1/3, 'CANESM5_r3p2':1/3}\n",
    "model_weights = xr.DataArray(\n",
    "    data=list(model_weights.values()),\n",
    "    dims=[\"model\"],\n",
    "    coords=dict(\n",
    "        model=([\"model\"], list(model_weights.keys()))\n",
    "    ),\n",
    "    attrs=dict(\n",
    "        description=\"weights for models\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our weights for models (grouping UKESM and CANESM realizations)\n",
    "onepct_model_weights = {'UKESM1_r1': 0.25, 'UKESM1_r2': 0.25, 'UKESM1_r3': 0.25, 'UKESM1_r4': 0.25, 'NORESM2': 1, 'GFDL': 1,\n",
    "       'MIROC': 1, 'CANESM5_r3p1':1/6, 'ACCESS':1, 'CANESM5_r2p2':1/6, 'CANESM5_r2p1':1/6,\n",
    "       'CANESM5_r1p2':1/6, 'CANESM5_r1p1':1/6, 'CANESM5_r3p2':1/6}\n",
    "onepct_model_weights = xr.DataArray(\n",
    "    data=list(onepct_model_weights.values()),\n",
    "    dims=[\"model\"],\n",
    "    coords=dict(\n",
    "        model=([\"model\"], list(onepct_model_weights.keys()))\n",
    "    ),\n",
    "    attrs=dict(\n",
    "        description=\"weights for models\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_model_weights = {'UKESM1_r1': 1, 'NORESM2': 1, 'GFDL': 1,\n",
    "       'MIROC': 1, 'ACCESS': 1,  'CANESM5_r1p2':1/3, 'CANESM5_r2p2':1/3, 'CANESM5_r3p2':1/3}\n",
    "G_model_weights = xr.DataArray(\n",
    "    data=list(G_model_weights.values()),\n",
    "    dims=[\"model\"],\n",
    "    coords=dict(\n",
    "        model=([\"model\"], list(G_model_weights.keys()))\n",
    "    ),\n",
    "    attrs=dict(\n",
    "        description=\"weights for Green's function\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PiCtrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#combine our picontrol data into one dataset, normalizing the time to year 0\n",
    "pictrl = {}\n",
    "for m in tas_co2_pictrl.keys():    \n",
    "    times = tas_co2_pictrl[m].time.get_index('time')\n",
    "    weights = times.shift(-1, 'MS') - times.shift(1, 'MS')\n",
    "    weights = xr.DataArray(weights, [('time', tas_co2_pictrl[m]['time'].values)]).astype('float')\n",
    "    pictrl[m] =  (tas_co2_pictrl[m] * weights).groupby('time.year').sum('time')/weights.groupby('time.year').sum('time')\n",
    "    pictrl[m]['year'] = pictrl[m]['year'] - pictrl[m]['year'][0] \n",
    "    \n",
    "for m in pictrl.keys():\n",
    "    pictrl[m] = pictrl[m].drop('height')\n",
    "ds_pictrl = xr.concat([pictrl[m] for m in pictrl.keys()], pd.Index([m for m in pictrl.keys()], name='model'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Mean Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "GF = G_ds.weighted(A).mean(dim = ['lat','lon'])\n",
    "\n",
    "conv_mean = {}\n",
    "for exp in ['1000gtc','1pct']:\n",
    "    conv_mean[exp] = {}\n",
    "    for m1 in ['UKESM1_r1','UKESM1_r2', 'UKESM1_r3', 'UKESM1_r4', 'NORESM2', 'ACCESS',\n",
    "       'GFDL', 'MIROC', 'CANESM5_r1p2', 'CANESM5_r2p2', 'CANESM5_r3p2']:\n",
    "        conv_mean[exp][m1] = {}\n",
    "        for t in ['pulse','cdr']:\n",
    "            if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "                m2 = 'UKESM1_r1'\n",
    "            else:\n",
    "                m2 = m1\n",
    "            conv_mean[exp][m1][t] = signal.convolve( np.array(GF.sel(model = m2, pulse_type = t).dropna(dim = 's')), np.array(emis_profile.sel(model = m1, experiment = exp)['emis']),'full')\n",
    "            conv_mean[exp][m1][t] = utils.np_to_xr_mean(conv_mean[exp][m1][t], GF.sel(model = m2, pulse_type = t), emis_profile.sel(model = m1, experiment = exp))\n",
    "            length = len(G_ds.weighted(A).mean(dim = ['lat','lon']).dropna(dim = 's')['s'])\n",
    "            conv_mean[exp][m1][t] = conv_mean[exp][m1][t][:length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataset\n",
    "\n",
    "conv_dict = {}\n",
    "for exp in conv_mean.keys():\n",
    "    conv_dict[exp] = {}\n",
    "    for m in conv_mean[exp].keys():\n",
    "        conv_dict[exp][m] = xr.concat([conv_mean[exp][m][t] for t in conv_mean[exp][m].keys()], pd.Index([t for t in conv_mean[exp][m].keys()], name='pulse_type'), coords='minimal')\n",
    "for exp in conv_mean.keys():\n",
    "    conv_dict[exp] = xr.concat([conv_dict[exp][m] for m in conv_mean[exp].keys()], pd.Index([m for m in conv_mean[exp].keys()], name='model'), coords='minimal')\n",
    "conv_mean_ds = xr.concat([conv_dict[exp] for exp in conv_dict.keys()], pd.Index([exp for exp in conv_dict.keys()], name='experiment'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reindex_df(df, weight_col):\n",
    "    \"\"\"expand the dataframe to prepare for resampling\n",
    "    result is 1 row per count per sample\"\"\"\n",
    "    df = df.reindex(df.index.repeat(df[weight_col]))\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "data = {'mean': conv_mean_ds.sel(experiment = '1000gtc').mean(dim = ['pulse_type']).sel(s = slice(60,80)).mean(dim = ['s']).values,\n",
    "        'model': conv_mean_ds.model.values,\n",
    "        'count': [3, 3, 3, 3, 12, 12, 12, 12, 4, 4, 4]}\n",
    "df_1000gtc_emulator = pd.DataFrame(data)\n",
    "df_1000gtc_emulator = reindex_df(df_1000gtc_emulator, weight_col = 'count')\n",
    "\n",
    "data = {'mean': conv_mean_ds.sel(experiment = '1pct').mean(dim = ['pulse_type']).sel(s = slice(60,80)).mean(dim = ['s']).values,\n",
    "        'model': conv_mean_ds.model.values,\n",
    "        'count': [3, 3, 3, 3, 12, 12, 12, 12, 4, 4, 4]}\n",
    "df_1pct_emulator = pd.DataFrame(data)\n",
    "df_1pct_emulator = reindex_df(df_1pct_emulator, weight_col = 'count')\n",
    "\n",
    "\n",
    "data = {'mean': ds_dif.where(ds_dif['model'].isin(model_weights.model.values), drop = True).sel(experiment = '1pct').sel(s = slice(60,80)).weighted(A).mean(dim = ['s', 'lon','lat'])['tas'].values,\n",
    "        'model': ds_dif.where(ds_dif['model'].isin(model_weights.model.values), drop = True).sel(experiment = '1pct').model.values,\n",
    "        'count': [3, 3, 3, 3, 12, 12, 12, 12, 4, 4, 4]}\n",
    "\n",
    "df_1pct_model = pd.DataFrame(data)\n",
    "df_1pct_model = reindex_df(df_1pct_model, weight_col = 'count')\n",
    "\n",
    "\n",
    "#######ZEC############\n",
    "\n",
    "data = {'mean': (conv_mean_ds.sel(experiment = '1000gtc').where(conv_mean_ds['model'].isin(list(model_run_1pct1000gtc_dict.keys())), drop = True).mean(dim = 'pulse_type').sel(\n",
    "                                                                s = slice(80-10, 80+10)).mean(dim = 's').weighted(A).mean(dim = ['lat','lon']) - \n",
    "                    conv_mean_ds.sel(experiment = '1000gtc').where(conv_mean_ds['model'].isin(list(model_run_1pct1000gtc_dict.keys())), drop = True).mean(dim = 'pulse_type').sel(s = 65).weighted(A).mean(dim = ['lat','lon'])).values,\n",
    "        'model': conv_mean_ds.where(conv_mean_ds['model'].isin(list(model_run_1pct1000gtc_dict.keys())), drop = True).model.values,\n",
    "        'count': [3, 3, 3, 3, 12, 12, 12, 4, 4, 4]}\n",
    "\n",
    "df_zec_emulator_model = pd.DataFrame(data)\n",
    "df_zec_emulator_model = reindex_df(df_zec_emulator_model, weight_col = 'count')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = {'mean': (ds_dif.where(ds_dif['model'].isin(list(model_run_1pct1000gtc_dict.keys())), drop = True).sel(experiment = '1000gtc').sel(\n",
    "                                                                s = slice(80-10, 80+10)).mean(dim = 's').weighted(A).mean(dim = ['lat','lon']) - \n",
    "                    ds_dif.where(ds_dif['model'].isin(list(model_run_1pct1000gtc_dict.keys())), drop = True).sel(experiment = '1000gtc').sel(s = 65).weighted(A).mean(dim = ['lat','lon']))['tas'].values,\n",
    "        \n",
    "        'model': ds_dif.where(ds_dif['model'].isin(list(model_run_1pct1000gtc_dict.keys())), drop = True).sel(experiment = '1000gtc').model.values,\n",
    "        'count': [3, 3, 3, 3, 12, 12, 12, 4, 4, 4]}\n",
    "\n",
    "df_zec_cmip_model = pd.DataFrame(data)\n",
    "df_zec_cmip_model = reindex_df(df_zec_cmip_model, weight_col = 'count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "GF = G_ds\n",
    "\n",
    "conv = {}\n",
    "for exp in ['1000gtc','1pct']:\n",
    "    print(exp)\n",
    "    conv[exp] = {}\n",
    "    if exp == '1000gtc':\n",
    "        model_list = ['UKESM1_r1', 'UKESM1_r2', 'UKESM1_r3', 'UKESM1_r4', 'NORESM2', 'MIROC', 'CANESM5_r1p2', 'CANESM5_r2p2', 'ACCESS', 'CANESM5_r3p2',]\n",
    "    elif exp == '1pct':\n",
    "        model_list = ['UKESM1_r1', 'UKESM1_r2', 'UKESM1_r3', 'UKESM1_r4', 'NORESM2', 'GFDL', 'MIROC', 'CANESM5_r1p2', 'CANESM5_r2p2', 'ACCESS', 'CANESM5_r3p2',]\n",
    "    for m1 in model_list:\n",
    "        conv[exp][m1] = {}\n",
    "        for t in ['pulse','cdr']:\n",
    "            if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "                m2 = 'UKESM1_r1'\n",
    "            else:\n",
    "                m2 = m1\n",
    "            print(m1, m2)\n",
    "            conv[exp][m1][t] = signal.convolve(np.array(GF.sel(model = m2, pulse_type = t).dropna(dim = 's')), \n",
    "                                               np.array(emis_profile.sel(model = m1, experiment = exp)['emis'])[~np.isnan(np.array(emis_profile.sel(model = m1, experiment = exp)['emis']))][..., None, None],\n",
    "                                               'full')\n",
    "            conv[exp][m1][t] = utils.np_to_xr(conv[exp][m1][t], GF.sel(model = m2, pulse_type = t), emis_profile.sel(model = m1, experiment = exp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dict[exp][m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.85 GiB for an array with shape (11, 2, 551, 180, 360) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m exp \u001b[38;5;129;01min\u001b[39;00m conv\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      9\u001b[0m     conv_dict[exp] \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mconcat([conv_dict[exp][m] \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m conv[exp]\u001b[38;5;241m.\u001b[39mkeys()], pd\u001b[38;5;241m.\u001b[39mIndex([m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m conv[exp]\u001b[38;5;241m.\u001b[39mkeys()], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m), coords\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m conv_ds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconv_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexperiment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mminimal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/xarray/core/concat.py:238\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan only concatenate xarray Dataset and DataArray \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(first_obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m     )\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombine_attrs\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/xarray/core/concat.py:578\u001b[0m, in \u001b[0;36m_dataarray_concat\u001b[0;34m(arrays, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    575\u001b[0m             arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mrename(name)\n\u001b[1;32m    576\u001b[0m     datasets\u001b[38;5;241m.\u001b[39mappend(arr\u001b[38;5;241m.\u001b[39m_to_temp_dataset())\n\u001b[0;32m--> 578\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43m_dataset_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m merged_attrs \u001b[38;5;241m=\u001b[39m merge_attrs([da\u001b[38;5;241m.\u001b[39mattrs \u001b[38;5;28;01mfor\u001b[39;00m da \u001b[38;5;129;01min\u001b[39;00m arrays], combine_attrs)\n\u001b[1;32m    592\u001b[0m result \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds, name)\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/xarray/core/concat.py:438\u001b[0m, in \u001b[0;36m_dataset_concat\u001b[0;34m(datasets, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Make sure we're working on a copy (we'll be loading variables)\u001b[39;00m\n\u001b[1;32m    436\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [ds\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[1;32m    437\u001b[0m datasets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m--> 438\u001b[0m     \u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m )\n\u001b[1;32m    441\u001b[0m dim_coords, dims_sizes, coord_names, data_names \u001b[38;5;241m=\u001b[39m _parse_datasets(datasets)\n\u001b[1;32m    442\u001b[0m dim_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(dim_coords)\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/xarray/core/alignment.py:368\u001b[0m, in \u001b[0;36malign\u001b[0;34m(join, copy, indexes, exclude, fill_value, *objects)\u001b[0m\n\u001b[1;32m    366\u001b[0m     new_obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     new_obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_indexers\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m new_obj\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mencoding\n\u001b[1;32m    372\u001b[0m result\u001b[38;5;241m.\u001b[39mappend(new_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/xarray/core/dataset.py:2948\u001b[0m, in \u001b[0;36mDataset.reindex\u001b[0;34m(self, indexers, method, tolerance, copy, fill_value, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   2744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreindex\u001b[39m(\n\u001b[1;32m   2745\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2746\u001b[0m     indexers: Mapping[Any, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2751\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mindexers_kwargs: Any,\n\u001b[1;32m   2752\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m   2753\u001b[0m     \u001b[38;5;124;03m\"\"\"Conform this object onto a new set of indexes, filling in\u001b[39;00m\n\u001b[1;32m   2754\u001b[0m \u001b[38;5;124;03m    missing values with ``fill_value``. The default fill value is NaN.\u001b[39;00m\n\u001b[1;32m   2755\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2946\u001b[0m \n\u001b[1;32m   2947\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2954\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2955\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mindexers_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/xarray/core/dataset.py:2977\u001b[0m, in \u001b[0;36mDataset._reindex\u001b[0;34m(self, indexers, method, tolerance, copy, fill_value, sparse, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   2974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bad_dims:\n\u001b[1;32m   2975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid reindex dimensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbad_dims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2977\u001b[0m variables, indexes \u001b[38;5;241m=\u001b[39m \u001b[43malignment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_variables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2978\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2979\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2980\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxindexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2986\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2988\u001b[0m coord_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coord_names)\n\u001b[1;32m   2989\u001b[0m coord_names\u001b[38;5;241m.\u001b[39mupdate(indexers)\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/xarray/core/alignment.py:639\u001b[0m, in \u001b[0;36mreindex_variables\u001b[0;34m(variables, sizes, indexes, indexers, method, tolerance, copy, fill_value, sparse)\u001b[0m\n\u001b[1;32m    636\u001b[0m needs_masking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;129;01min\u001b[39;00m masked_dims \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m var\u001b[38;5;241m.\u001b[39mdims)\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_masking:\n\u001b[0;32m--> 639\u001b[0m     new_var \u001b[38;5;241m=\u001b[39m \u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_full_slice(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m key):\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# no reindexing necessary\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# here we need to manually deal with copying data, since\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;66;03m# we neither created a new ndarray nor used fancy indexing\u001b[39;00m\n\u001b[1;32m    644\u001b[0m     new_var \u001b[38;5;241m=\u001b[39m var\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/xarray/core/variable.py:817\u001b[0m, in \u001b[0;36mVariable._getitem_with_mask\u001b[0;34m(self, key, fill_value)\u001b[0m\n\u001b[1;32m    813\u001b[0m     mask \u001b[38;5;241m=\u001b[39m indexing\u001b[38;5;241m.\u001b[39mcreate_mask(indexer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, data)\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;66;03m# we need to invert the mask in order to pass data first. This helps\u001b[39;00m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;66;03m# pint to choose the correct unit\u001b[39;00m\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;66;03m# TODO: revert after https://github.com/hgrecco/pint/issues/1019 is fixed\u001b[39;00m\n\u001b[0;32m--> 817\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mduck_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_not\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;66;03m# array cannot be indexed along dimensions of size 0, so just\u001b[39;00m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# build the mask directly instead.\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     mask \u001b[38;5;241m=\u001b[39m indexing\u001b[38;5;241m.\u001b[39mcreate_mask(indexer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/xarray/core/duck_array_ops.py:268\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(condition, x, y)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwhere\u001b[39m(condition, x, y):\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;124;03m\"\"\"Three argument where() with better dtype promotion rules.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_where\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mas_shared_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 5.85 GiB for an array with shape (11, 2, 551, 180, 360) and data type float64"
     ]
    }
   ],
   "source": [
    "#convert to dataset\n",
    "\n",
    "conv_dict = {}\n",
    "for exp in conv.keys():\n",
    "    conv_dict[exp] = {}\n",
    "    for m in conv[exp].keys():\n",
    "        conv_dict[exp][m] = xr.concat([conv[exp][m][t] for t in conv[exp][m].keys()], pd.Index([t for t in conv[exp][m].keys()], name='pulse_type'), coords='minimal')\n",
    "for exp in conv.keys():\n",
    "    conv_dict[exp] = xr.concat([conv_dict[exp][m] for m in conv[exp].keys()], pd.Index([m for m in conv[exp].keys()], name='model'), coords='minimal')\n",
    "conv_ds = xr.concat([conv_dict[exp] for exp in conv_dict.keys()], pd.Index([exp for exp in conv_dict.keys()], name='experiment'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_mean_ds.to_netcdf('Outputs/conv_mean_ds.nc4')\n",
    "\n",
    "conv_ds.to_netcdf('Outputs/conv_ds.nc4')\n",
    "\n",
    "emis_profile.to_netcdf('Outputs/emis_profile.nc4')\n",
    "\n",
    "ds_dif.to_netcdf('Outputs/ds_dif.nc4')\n",
    "\n",
    "ds_pictrl.to_netcdf('Outputs/ds_pictrl.nc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gchp)",
   "language": "python",
   "name": "gchp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
