{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cftime\n",
    "import dask\n",
    "#import xarrayutils\n",
    "import cartopy.crs as ccrs\n",
    "from xmip.preprocessing import combined_preprocessing\n",
    "from xmip.preprocessing import replace_x_y_nominal_lat_lon\n",
    "from xmip.drift_removal import replace_time\n",
    "from xmip.postprocessing import concat_experiments\n",
    "import xmip.drift_removal as xm_dr\n",
    "import xmip as xm\n",
    "import xesmf as xe\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "\n",
    "\n",
    "import cf_xarray as cfxr\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.signal as signal\n",
    "from scipy import stats\n",
    "from datetime import timedelta\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import cmocean\n",
    "import cmocean.cm as cmo\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7f4ffdfa6d00>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(**{'array.slicing.split_large_chunks': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ds_path = 'Outputs/G_pulse_ds.nc4'\n",
    "G_cdr_ds_path = 'Outputs/G_cdr_ds.nc4'\n",
    "\n",
    "G_ds = utils.import_polyfit_G(G_ds_path, G_cdr_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run_pulse_dict = utils.model_run_pulse_dict\n",
    "model_run_cdr_pulse_dict = utils.model_run_cdr_pulse_dict\n",
    "model_run_control_dict = {'CANESM5_r1p1':'CanESM5_piControl_r1i1p1f1*',}\n",
    "\n",
    "\n",
    "model_run_hist_co2_dict = {'CANESM5_r1p1':'CanESM5_hist-CO2_r1i1p1f1*',\n",
    "                      'CANESM5_r2p1':'CanESM5_hist-CO2_r2i1p1f1*',\n",
    "                      'CANESM5_r3p1':'CanESM5_hist-CO2_r3i1p1f1*',\n",
    "                      'CANESM5_r4p1':'CanESM5_hist-CO2_r4i1p1f1*',\n",
    "                      'CANESM5_r5p1':'CanESM5_hist-CO2_r5i1p1f1*',\n",
    "                      'CANESM5_r6p1':'CanESM5_hist-CO2_r6i1p1f1*',\n",
    "                      'CANESM5_r7p1':'CanESM5_hist-CO2_r7i1p1f1*',\n",
    "                      'CANESM5_r8p1':'CanESM5_hist-CO2_r8i1p1f1*',\n",
    "                      'CANESM5_r9p1':'CanESM5_hist-CO2_r9i1p1f1*'}\n",
    "\n",
    "model_run_control_co2mass_dict = {'CANESM5_r1p1':'CanESM5-1_piControl_r1i1p1f1*',} #we have the mass from r1i1p1f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_color = utils.model_color\n",
    "type_color = utils.type_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = utils.A\n",
    "ds_out = utils.ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n",
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n",
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n",
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n",
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n",
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n",
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n",
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n",
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    }
   ],
   "source": [
    "tas_co2_ssp245 = {}\n",
    "tas_co2_ssp245_GHG = {}\n",
    "tas_co2_ssp245_nat = {}\n",
    "tas_co2_pictrl = {}\n",
    "tas_hist = {}\n",
    "\n",
    "for m in model_run_hist_co2_dict.keys():\n",
    "    tas_hist[m] = xr.open_mfdataset(f'cmip6_data/tas_Amon_{model_run_hist_co2_dict[m]}',  use_cftime=True) #kg/m2/s\n",
    "    lat_corners = cfxr.bounds_to_vertices(tas_hist[m].isel(time = 0)['lat_bnds'], \"bnds\", order=None)\n",
    "    lon_corners = cfxr.bounds_to_vertices(tas_hist[m].isel(time = 0)['lon_bnds'], \"bnds\", order=None)\n",
    "    tas_hist[m] = tas_hist[m].assign(lon_b=lon_corners, lat_b=lat_corners)\n",
    "    tas_hist[m] = utils._regrid_ds(tas_hist[m], ds_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emfreese/anaconda3/envs/gchp/lib/python3.9/site-packages/xesmf/frontend.py:555: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  ds_out = xr.apply_ufunc(\n"
     ]
    }
   ],
   "source": [
    "for m in model_run_control_dict.keys():\n",
    "    tas_co2_pictrl[m] = xr.open_mfdataset(f'cmip6_data/tas_Amon_{model_run_control_dict[m]}',  use_cftime=True) #kg/m2/s\n",
    "    lat_corners = cfxr.bounds_to_vertices(tas_co2_pictrl[m].isel(time = 0)['lat_bnds'], \"bnds\", order=None)\n",
    "    lon_corners = cfxr.bounds_to_vertices(tas_co2_pictrl[m].isel(time = 0)['lon_bnds'], \"bnds\", order=None)\n",
    "    tas_co2_pictrl[m] = tas_co2_pictrl[m].assign(lon_b=lon_corners, lat_b=lat_corners)\n",
    "    tas_co2_pictrl[m] = utils._regrid_ds(tas_co2_pictrl[m], ds_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yrs = {}\n",
    "for m in list(tas_hist.keys()):\n",
    "    yrs[m] = (datetime.datetime.strptime(tas_hist[m].attrs['YMDH_branch_time_in_parent'],\"%Y:%m:%d:%H\").year - \n",
    "            datetime.datetime.strptime(tas_hist['CANESM5_r1p1'].attrs['YMDH_branch_time_in_parent'],\"%Y:%m:%d:%H\").year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix the times so that they line up according to the notes above\n",
    "\n",
    "\n",
    "for m in tas_hist.keys():\n",
    "    yrs = (datetime.datetime.strptime(tas_hist[m].attrs['YMDH_branch_time_in_parent'],\"%Y:%m:%d:%H\").year  - \n",
    "             datetime.datetime.strptime(tas_hist['CANESM5_r1p1'].attrs['YMDH_branch_time_in_parent'],\"%Y:%m:%d:%H\").year)\n",
    "\n",
    "    tas_hist[m]['time'] = tas_hist[m]['time'] + timedelta(365*yrs)\n",
    "\n",
    "\n",
    "m = 'CANESM5_r1p1'\n",
    "tas_co2_pictrl[m]['time'] = tas_co2_pictrl[m]['time']- timedelta(365*3351)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 2052, lon: 360, lat: 180)\n",
      "Coordinates:\n",
      "  * time     (time) object 1850-01-16 12:00:00 ... 2020-12-16 12:00:00\n",
      "    height   float64 2.0\n",
      "  * lon      (lon) int64 0 1 2 3 4 5 6 7 8 ... 352 353 354 355 356 357 358 359\n",
      "  * lat      (lat) float64 -89.5 -88.5 -87.5 -86.5 -85.5 ... 86.5 87.5 88.5 89.5\n",
      "Data variables:\n",
      "    tas      (time, lat, lon) float64 dask.array<chunksize=(257, 180, 360), meta=np.ndarray>\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 2052, lon: 360, lat: 180)\n",
      "Coordinates:\n",
      "  * time     (time) object 1950-01-16 12:00:00 ... 2120-12-16 12:00:00\n",
      "    height   float64 2.0\n",
      "  * lon      (lon) int64 0 1 2 3 4 5 6 7 8 ... 352 353 354 355 356 357 358 359\n",
      "  * lat      (lat) float64 -89.5 -88.5 -87.5 -86.5 -85.5 ... 86.5 87.5 88.5 89.5\n",
      "Data variables:\n",
      "    tas      (time, lat, lon) float64 dask.array<chunksize=(240, 180, 360), meta=np.ndarray>\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 2052, lon: 360, lat: 180)\n",
      "Coordinates:\n",
      "  * time     (time) object 2050-01-16 12:00:00 ... 2220-12-16 12:00:00\n",
      "    height   float64 2.0\n",
      "  * lon      (lon) int64 0 1 2 3 4 5 6 7 8 ... 352 353 354 355 356 357 358 359\n",
      "  * lat      (lat) float64 -89.5 -88.5 -87.5 -86.5 -85.5 ... 86.5 87.5 88.5 89.5\n",
      "Data variables:\n",
      "    tas      (time, lat, lon) float64 dask.array<chunksize=(257, 180, 360), meta=np.ndarray>\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 2052, lon: 360, lat: 180)\n",
      "Coordinates:\n",
      "  * time     (time) object 2150-01-16 12:00:00 ... 2320-12-16 12:00:00\n",
      "    height   float64 2.0\n",
      "  * lon      (lon) int64 0 1 2 3 4 5 6 7 8 ... 352 353 354 355 356 357 358 359\n",
      "  * lat      (lat) float64 -89.5 -88.5 -87.5 -86.5 -85.5 ... 86.5 87.5 88.5 89.5\n",
      "Data variables:\n",
      "    tas      (time, lat, lon) float64 dask.array<chunksize=(240, 180, 360), meta=np.ndarray>\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 2052, lon: 360, lat: 180)\n",
      "Coordinates:\n",
      "  * time     (time) object 2250-01-16 12:00:00 ... 2420-12-16 12:00:00\n",
      "    height   float64 2.0\n",
      "  * lon      (lon) int64 0 1 2 3 4 5 6 7 8 ... 352 353 354 355 356 357 358 359\n",
      "  * lat      (lat) float64 -89.5 -88.5 -87.5 -86.5 -85.5 ... 86.5 87.5 88.5 89.5\n",
      "Data variables:\n",
      "    tas      (time, lat, lon) float64 dask.array<chunksize=(257, 180, 360), meta=np.ndarray>\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 2052, lon: 360, lat: 180)\n",
      "Coordinates:\n",
      "  * time     (time) object 2350-01-16 12:00:00 ... 2520-12-16 12:00:00\n",
      "    height   float64 2.0\n",
      "  * lon      (lon) int64 0 1 2 3 4 5 6 7 8 ... 352 353 354 355 356 357 358 359\n",
      "  * lat      (lat) float64 -89.5 -88.5 -87.5 -86.5 -85.5 ... 86.5 87.5 88.5 89.5\n",
      "Data variables:\n",
      "    tas      (time, lat, lon) float64 dask.array<chunksize=(240, 180, 360), meta=np.ndarray>\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 2052, lon: 360, lat: 180)\n",
      "Coordinates:\n",
      "  * time     (time) object 2450-01-16 12:00:00 ... 2620-12-16 12:00:00\n",
      "    height   float64 2.0\n",
      "  * lon      (lon) int64 0 1 2 3 4 5 6 7 8 ... 352 353 354 355 356 357 358 359\n",
      "  * lat      (lat) float64 -89.5 -88.5 -87.5 -86.5 -85.5 ... 86.5 87.5 88.5 89.5\n",
      "Data variables:\n",
      "    tas      (time, lat, lon) float64 dask.array<chunksize=(257, 180, 360), meta=np.ndarray>\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 2052, lon: 360, lat: 180)\n",
      "Coordinates:\n",
      "  * time     (time) object 2550-01-16 12:00:00 ... 2720-12-16 12:00:00\n",
      "    height   float64 2.0\n",
      "  * lon      (lon) int64 0 1 2 3 4 5 6 7 8 ... 352 353 354 355 356 357 358 359\n",
      "  * lat      (lat) float64 -89.5 -88.5 -87.5 -86.5 -85.5 ... 86.5 87.5 88.5 89.5\n",
      "Data variables:\n",
      "    tas      (time, lat, lon) float64 dask.array<chunksize=(240, 180, 360), meta=np.ndarray>\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 2052, lon: 360, lat: 180)\n",
      "Coordinates:\n",
      "  * time     (time) object 2650-01-16 12:00:00 ... 2820-12-16 12:00:00\n",
      "    height   float64 2.0\n",
      "  * lon      (lon) int64 0 1 2 3 4 5 6 7 8 ... 352 353 354 355 356 357 358 359\n",
      "  * lat      (lat) float64 -89.5 -88.5 -87.5 -86.5 -85.5 ... 86.5 87.5 88.5 89.5\n",
      "Data variables:\n",
      "    tas      (time, lat, lon) float64 dask.array<chunksize=(257, 180, 360), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "dif_hist = {}\n",
    "for m1 in model_run_hist_co2_dict.keys():\n",
    "    m2 = 'CANESM5_r1p1'\n",
    "    \n",
    "    dif_hist[m1] = tas_hist[m1] - tas_co2_pictrl[m2]#.isel(time = slice(yrs[m1]*12,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfBoundsDatetime",
     "evalue": "Out of bounds nanosecond timestamp: 100-01-01 00:00:00",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [206]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     if len(dif_hist[m1]['time']) > 3000:  #hack to get the time stamping to work, should find better fix\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#         periods = 3000\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     else:\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     periods \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dif_hist[m1][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m     times \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate_range\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0100\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mperiods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     weights \u001b[38;5;241m=\u001b[39m times\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMS\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m times\n\u001b[1;32m     14\u001b[0m     weights \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(weights, [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, dif_hist[m1][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m][:periods]\u001b[38;5;241m.\u001b[39mvalues)])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/pandas/core/indexes/datetimes.py:1070\u001b[0m, in \u001b[0;36mdate_range\u001b[0;34m(start, end, periods, freq, tz, normalize, name, closed, inclusive, **kwargs)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m freq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m com\u001b[38;5;241m.\u001b[39many_none(periods, start, end):\n\u001b[1;32m   1068\u001b[0m     freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1070\u001b[0m dtarr \u001b[38;5;241m=\u001b[39m \u001b[43mDatetimeArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_range\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperiods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperiods\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclusive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclusive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatetimeIndex\u001b[38;5;241m.\u001b[39m_simple_new(dtarr, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py:412\u001b[0m, in \u001b[0;36mDatetimeArray._generate_range\u001b[0;34m(cls, start, end, periods, freq, tz, normalize, ambiguous, nonexistent, inclusive)\u001b[0m\n\u001b[1;32m    409\u001b[0m freq \u001b[38;5;241m=\u001b[39m to_offset(freq)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[43mTimestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    415\u001b[0m     end \u001b[38;5;241m=\u001b[39m Timestamp(end)\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/pandas/_libs/tslibs/timestamps.pyx:1399\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timestamps.Timestamp.__new__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/pandas/_libs/tslibs/conversion.pyx:408\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_to_tsobject\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/pandas/_libs/tslibs/conversion.pyx:642\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion._convert_str_to_tsobject\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/pandas/_libs/tslibs/conversion.pyx:627\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion._convert_str_to_tsobject\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/gchp/lib/python3.9/site-packages/pandas/_libs/tslibs/np_datetime.pyx:120\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.np_datetime.check_dts_bounds\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 100-01-01 00:00:00"
     ]
    }
   ],
   "source": [
    "dif_hist = {}\n",
    "for m1 in model_run_hist_co2_dict.keys():\n",
    "    m2 = 'CANESM5_r1p1'\n",
    "    \n",
    "    dif_hist[m1] = tas_hist[m1] - tas_co2_pictrl[m2]\n",
    "    \n",
    "    if len(dif_hist[m1]['time']) > 3000:  #hack to get the time stamping to work, should find better fix\n",
    "        periods = 3000\n",
    "    else:\n",
    "        periods = len(dif_hist[m1]['time'])\n",
    "        \n",
    "    times = pd.date_range('0100', periods= periods, freq='MS')\n",
    "    weights = times.shift(1, 'MS') - times\n",
    "    weights = xr.DataArray(weights, [('time', dif_hist[m1]['time'][:periods].values)]).astype('float')\n",
    "    dif_hist[m1] =  (dif_hist[m1] * weights).groupby('time.year').sum('time')/weights.groupby('time.year').sum('time')\n",
    "\n",
    "    dif_hist[m1]['year'] = range(len(dif_hist[m1]['year']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in dif_hist.keys():\n",
    "    dif_hist[m] = dif_hist[m].drop('height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dif_hist = xr.concat([dif_hist[m] for m in dif_hist.keys()], pd.Index([m for m in dif_hist.keys()], name='model'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dif = ds_dif_hist.rename({'year':'s'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emissions profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emis_profile =  xr.open_dataset(f'Outputs/hist_co2_only_emis_profile_full.nc4')\n",
    "emis_profile = emis_profile.rename({'__xarray_dataarray_variable__':'emis'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_model_weights = {'UKESM1_r1': 1, 'NORESM2': 1, 'GFDL': 1,\n",
    "       'MIROC': 1, 'ACCESS': 1,  'CANESM5_r1p2':1/3, 'CANESM5_r2p2':1/3, 'CANESM5_r3p2':1/3}\n",
    "G_model_weights = xr.DataArray(\n",
    "    data=list(G_model_weights.values()),\n",
    "    dims=[\"model\"],\n",
    "    coords=dict(\n",
    "        model=([\"model\"], list(G_model_weights.keys()))\n",
    "    ),\n",
    "    attrs=dict(\n",
    "        description=\"weights for Green's function\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PiCtrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#combine our picontrol data into one dataset, normalizing the time to year 0\n",
    "pictrl = {}\n",
    "for m in tas_co2_pictrl.keys():    \n",
    "    times = tas_co2_pictrl[m].time.get_index('time')\n",
    "    weights = times.shift(-1, 'MS') - times.shift(1, 'MS')\n",
    "    weights = xr.DataArray(weights, [('time', tas_co2_pictrl[m]['time'].values)]).astype('float')\n",
    "    pictrl[m] =  (tas_co2_pictrl[m] * weights).groupby('time.year').sum('time')/weights.groupby('time.year').sum('time')\n",
    "    pictrl[m]['year'] = pictrl[m]['year'] - pictrl[m]['year'][0] \n",
    "    \n",
    "for m in pictrl.keys():\n",
    "    pictrl[m] = pictrl[m].drop('height')\n",
    "ds_pictrl = xr.concat([pictrl[m] for m in pictrl.keys()], pd.Index([m for m in pictrl.keys()], name='model'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Mean Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.6 s, sys: 9.85 s, total: 42.5 s\n",
      "Wall time: 42.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GF = G_ds.weighted(A).mean(dim = ['lat','lon'])\n",
    "\n",
    "conv_mean = {}\n",
    "for m1 in emis_profile.model.values:\n",
    "    conv_mean[m1] = {}\n",
    "    for t in ['pulse','cdr']:\n",
    "        m2 = 'CANESM5_r1p2'\n",
    "        conv_mean[m1][t] = signal.convolve( np.array(GF.sel(model = m2, pulse_type = t).dropna(dim = 's')), np.array(emis_profile['emis'].sel(model = m1)),'full')\n",
    "        conv_mean[m1][t] = utils.np_to_xr_mean(conv_mean[m1][t], GF.sel(model = m2, pulse_type = t), emis_profile.sel(model = m1))\n",
    "        length = len(G_ds.weighted(A).mean(dim = ['lat','lon']).dropna(dim = 's')['s'])\n",
    "        conv_mean[m1][t] = conv_mean[m1][t][:length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataset\n",
    "\n",
    "conv_dict = {}\n",
    "\n",
    "for m1 in conv_mean.keys():\n",
    "    conv_dict[m1] = xr.concat([conv_mean[m1][t] for t in conv_mean[m1].keys()], pd.Index([t for t in conv_mean[m1].keys()], name='pulse_type'), coords='minimal')\n",
    "conv_mean_ds = xr.concat([conv_dict[m1] for m1 in conv_dict.keys()], pd.Index([m1 for m1 in conv_dict.keys()], name='model'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.7 s, sys: 5.34 s, total: 16 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "GF = G_ds\n",
    "\n",
    "conv = {}\n",
    "for m1 in emis_profile.model.values:\n",
    "    conv[m1] = {}\n",
    "    for t in ['pulse','cdr']:\n",
    "        m2 = 'CANESM5_r1p2'\n",
    "        conv[m1][t] = signal.convolve(np.array(GF.sel(model = m2, pulse_type = t).dropna(dim = 's')), \n",
    "                                      np.array(emis_profile['emis'].sel(model = m1))[..., None, None],\n",
    "                                      'full')\n",
    "        conv[m1][t] = utils.np_to_xr(conv[m1][t], \n",
    "                                          GF.sel(model = m2, pulse_type = t), \n",
    "                                          emis_profile.sel(model = m1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataset\n",
    "\n",
    "conv_dict = {}\n",
    "\n",
    "for m1 in conv.keys():\n",
    "    conv_dict[m1] = xr.concat([conv[m1][t] for t in conv[m1].keys()], pd.Index([t for t in conv[m1].keys()], name='pulse_type'), coords='minimal')\n",
    "conv_ds = xr.concat([conv_dict[m1] for m1 in conv_dict.keys()], pd.Index([m1 for m1 in conv_dict.keys()], name='model'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Mean Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.4 s, sys: 20.9 s, total: 1min\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "GF = G_ds\n",
    "\n",
    "conv = {}\n",
    "for m1 in emis_profile.model.values:\n",
    "    conv[m1] = {}\n",
    "    for t in ['pulse','cdr']:\n",
    "        conv[m1][t] = signal.convolve(np.array(GF.sel(pulse_type = t).dropna(dim = 's').mean(dim = 'model')), \n",
    "                                      np.array(emis_profile['emis'].sel(model = m1))[..., None, None],\n",
    "                                      'full')\n",
    "        conv[m1][t] = utils.np_to_xr(conv[m1][t], \n",
    "                                          GF.sel(pulse_type = t).mean(dim = 'model'), \n",
    "                                          emis_profile.sel(model = m1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataset\n",
    "\n",
    "conv_dict = {}\n",
    "\n",
    "for m1 in conv.keys():\n",
    "    conv_dict[m1] = xr.concat([conv[m1][t] for t in conv[m1].keys()], pd.Index([t for t in conv[m1].keys()], name='pulse_type'), coords='minimal')\n",
    "conv_mod_mean_ds = xr.concat([conv_dict[m1] for m1 in conv_dict.keys()], pd.Index([m1 for m1 in conv_dict.keys()], name='model'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_mod_mean_ds.to_netcdf('Outputs/hist_co2_only_mod_mean_conv_ds.nc4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_mean_ds.to_netcdf('Outputs/hist_co2_only_conv_mean_ds.nc4')\n",
    "\n",
    "conv_ds.to_netcdf('Outputs/hist_co2_only_conv_ds.nc4')\n",
    "\n",
    "conv_mod_mean_ds.to_netcdf('Outputs/hist_co2_only_conv_ds.nc4')\n",
    "\n",
    "emis_profile.to_netcdf('Outputs/hist_co2_only_emis_profile.nc4')\n",
    "\n",
    "ds_dif.to_netcdf('Outputs/hist_co2_only_ds_dif.nc4')\n",
    "\n",
    "#ds_pictrl.to_netcdf('Outputs/ssp45_ds_pictrl.nc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gchp)",
   "language": "python",
   "name": "gchp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
