{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cftime\n",
    "import dask\n",
    "import xarrayutils\n",
    "import cartopy.crs as ccrs\n",
    "from xmip.preprocessing import combined_preprocessing\n",
    "from xmip.preprocessing import replace_x_y_nominal_lat_lon\n",
    "from xmip.drift_removal import replace_time\n",
    "from xmip.postprocessing import concat_experiments\n",
    "import xmip.drift_removal as xm_dr\n",
    "import xmip as xm\n",
    "import xesmf as xe\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import utils\n",
    "import cf_xarray as cfxr\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.signal as signal\n",
    "from scipy import stats\n",
    "from datetime import timedelta\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import cmocean\n",
    "import cmocean.cm as cmo\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7fb7e039c250>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(**{'array.slicing.split_large_chunks': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ds_path = 'Outputs/G_pulse_ds.nc4'\n",
    "G_cdr_ds_path = 'Outputs/G_cdr_ds.nc4'\n",
    "\n",
    "G_ds = utils.import_polyfit_G(G_ds_path, G_cdr_ds_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "GFDL: 1pct and esm pi-control start from year 0001\n",
    "\n",
    "UKESM1: 1pct starts in 1850 and pi-control starts in 1960, move 1pct to start in 1960\n",
    "\n",
    "MIROC: both start from 1850\n",
    "\n",
    "NORESM2: 1pct from 0001 pi-control from 1600-- move 1pct to 1600\n",
    "\n",
    "ACCESS: 1pct and pi-control from 0101\n",
    "\n",
    "CANESM5_r1p2: 1pct 1850, pi-control 5550, move 1pct to 5550\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run_pulse_dict = utils.model_run_pulse_dict\n",
    "model_run_1pct_dict = utils.model_run_1pct_dict\n",
    "model_run_control_dict = utils.model_run_picontrol_dict\n",
    "model_run_cdr_pulse_dict = utils.model_run_cdr_pulse_dict\n",
    "model_run_1pct1000gtc_dict = utils.model_run_1pct_1000gtc_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_color = utils.model_color\n",
    "type_color = utils.type_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = utils.A\n",
    "ds_out = utils.ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_co2_1pct1000gtc = {}\n",
    "tas_co2_pictrl = {}\n",
    "tas_1pct = {}\n",
    "\n",
    "for m in model_run_1pct_dict.keys():\n",
    "    print(m)\n",
    "    print('tas')\n",
    "    tas_1pct[m] = xr.open_mfdataset(f'cmip6_data/tas_Amon_{model_run_1pct_dict[m]}',  use_cftime=True) #kg/m2/s\n",
    "    lat_corners = cfxr.bounds_to_vertices(tas_1pct[m].isel(time = 0)['lat_bnds'], \"bnds\", order=None)\n",
    "    lon_corners = cfxr.bounds_to_vertices(tas_1pct[m].isel(time = 0)['lon_bnds'], \"bnds\", order=None)\n",
    "    tas_1pct[m] = tas_1pct[m].assign(lon_b=lon_corners, lat_b=lat_corners)\n",
    "    tas_1pct[m] = utils._regrid_ds(tas_1pct[m], ds_out)\n",
    "    \n",
    "    \n",
    "for m in model_run_1pct1000gtc_dict.keys():\n",
    "    print(m)\n",
    "    print('tas')\n",
    "    tas_co2_1pct1000gtc[m] = xr.open_mfdataset(f'cmip6_data/tas_Amon_{model_run_1pct1000gtc_dict[m]}',  use_cftime=True) #kg/m2/s\n",
    "    lat_corners = cfxr.bounds_to_vertices(tas_co2_1pct1000gtc[m].isel(time = 0)['lat_bnds'], \"bnds\", order=None)\n",
    "    lon_corners = cfxr.bounds_to_vertices(tas_co2_1pct1000gtc[m].isel(time = 0)['lon_bnds'], \"bnds\", order=None)\n",
    "    tas_co2_1pct1000gtc[m] = tas_co2_1pct1000gtc[m].assign(lon_b=lon_corners, lat_b=lat_corners)\n",
    "    tas_co2_1pct1000gtc[m] = utils._regrid_ds(tas_co2_1pct1000gtc[m], ds_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in tas_co2_1pct1000gtc.keys():\n",
    "    tas_co2_1pct1000gtc[m] = xr.concat([tas_1pct[m].loc[dict(time = slice(tas_1pct[m]['time'].min(), tas_co2_1pct1000gtc[m]['time'].min()-timedelta(30)))] , \n",
    "                                        tas_co2_1pct1000gtc[m]],\n",
    "                 dim = 'time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model_run_control_dict.keys():\n",
    "    print(m)\n",
    "    print('tas')\n",
    "    tas_co2_pictrl[m] = xr.open_mfdataset(f'cmip6_data/tas_Amon_{model_run_control_dict[m]}',  use_cftime=True) #kg/m2/s\n",
    "    lat_corners = cfxr.bounds_to_vertices(tas_co2_pictrl[m].isel(time = 0)['lat_bnds'], \"bnds\", order=None)\n",
    "    lon_corners = cfxr.bounds_to_vertices(tas_co2_pictrl[m].isel(time = 0)['lon_bnds'], \"bnds\", order=None)\n",
    "    tas_co2_pictrl[m] = tas_co2_pictrl[m].assign(lon_b=lon_corners, lat_b=lat_corners)\n",
    "    tas_co2_pictrl[m] = utils._regrid_ds(tas_co2_pictrl[m], ds_out)\n",
    "\n",
    "## fix the times so that they line up according to the notes above\n",
    "m = 'NORESM2'\n",
    "tas_co2_pictrl[m]['time'] = tas_co2_pictrl[m]['time'] -timedelta(365*1599)\n",
    "\n",
    "m = 'UKESM1_r1'\n",
    "tas_co2_pictrl[m]['time'] = tas_co2_pictrl[m]['time'] - timedelta(360*110)\n",
    "\n",
    "m = 'CANESM5_r1p2'\n",
    "tas_co2_pictrl[m]['time'] = tas_co2_pictrl[m]['time']- timedelta(365*3700)\n",
    "\n",
    "m = 'CANESM5_r1p1'\n",
    "tas_co2_pictrl[m]['time'] = tas_co2_pictrl[m]['time']- timedelta(365*3351)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_1000gtc = {}\n",
    "for m1 in model_run_1pct1000gtc_dict.keys():\n",
    "    print(m1)\n",
    "    if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "        m2 = 'UKESM1_r1'\n",
    "    elif m1 == 'CANESM5_r1p2' or m1 == 'CANESM5_r2p2' or m1 == 'CANESM5_r3p2' or m1 == 'CANESM5_r4p2' or m1 == 'CANESM5_r5p2':\n",
    "         m2 = 'CANESM5_r1p2'\n",
    "    else:\n",
    "        m2 = m1\n",
    "    print(m1, m2)\n",
    "    \n",
    "    dif_1000gtc[m1] = tas_co2_1pct1000gtc[m1] - tas_co2_pictrl[m2]\n",
    "    \n",
    "    if len(dif_1000gtc[m1]['time']) > 3000:  #hack to get the time stamping to work, should find better fix\n",
    "        periods = 3000\n",
    "    else:\n",
    "        periods = len(dif_1000gtc[m1]['time'])\n",
    "        \n",
    "    times = pd.date_range('2000', periods= periods, freq='MS')\n",
    "    weights = times.shift(1, 'MS') - times\n",
    "    weights = xr.DataArray(weights, [('time', dif_1000gtc[m1]['time'][:periods].values)]).astype('float')\n",
    "    dif_1000gtc[m1] =  (dif_1000gtc[m1] * weights).groupby('time.year').sum('time')/weights.groupby('time.year').sum('time')\n",
    "\n",
    "    dif_1000gtc[m1]['year'] = range(len(dif_1000gtc[m1]['year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_1pct = {}\n",
    "for m1 in model_run_1pct_dict.keys():\n",
    "    if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "        m2 = 'UKESM1_r1'\n",
    "    elif m1 == 'CANESM5_r1p1' or m1 == 'CANESM5_r2p1' or m1 == 'CANESM5_r3p1':\n",
    "         m2 = 'CANESM5_r1p1'\n",
    "    elif m1 == 'CANESM5_r1p2' or m1 == 'CANESM5_r2p2' or m1 == 'CANESM5_r3p2':\n",
    "         m2 = 'CANESM5_r1p2'\n",
    "    else:\n",
    "        m2 = m1\n",
    "    print(m1, m2)\n",
    "    \n",
    "    \n",
    "    dif_1pct[m1] = tas_1pct[m1] - tas_co2_pictrl[m2]\n",
    "    \n",
    "    if len(dif_1pct[m1]['time']) > 3000:  #hack to get the time stamping to work, should find better fix\n",
    "        periods = 3000\n",
    "    else:\n",
    "        periods = len(dif_1pct[m1]['time'])\n",
    "        \n",
    "    times = pd.date_range('2000', periods= periods, freq='MS')\n",
    "    weights = times.shift(1, 'MS') - times\n",
    "    weights = xr.DataArray(weights, [('time', dif_1pct[m1]['time'][:periods].values)]).astype('float')\n",
    "    dif_1pct[m1] =  (dif_1pct[m1] * weights).groupby('time.year').sum('time')/weights.groupby('time.year').sum('time')\n",
    "\n",
    "    dif_1pct[m1]['year'] = range(len(dif_1pct[m1]['year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in dif_1pct.keys():\n",
    "    dif_1pct[m] = dif_1pct[m].drop('height')\n",
    "for m in dif_1000gtc.keys():\n",
    "    dif_1000gtc[m] = dif_1000gtc[m].drop('height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of height and limit the time to the length of the GF\n",
    "for m1 in ['UKESM1_r1', 'UKESM1_r2', 'UKESM1_r3', 'UKESM1_r4', 'NORESM2',\n",
    "       'GFDL', 'MIROC', 'CANESM5_r1p2', 'CANESM5_r2p2', 'ACCESS', 'CANESM5_r3p2']:\n",
    "    \n",
    "    for t in ['pulse','cdr']:\n",
    "        if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "            m2 = 'UKESM1_r1'\n",
    "        elif m1 == 'CANESM5_r1p1' or m1 == 'CANESM5_r2p1' or m1 == 'CANESM5_r3p1':\n",
    "             m2 = 'CANESM5_r1p1'\n",
    "        elif m1 == 'CANESM5_r1p2' or m1 == 'CANESM5_r2p2' or m1 == 'CANESM5_r3p2':\n",
    "             m2 = 'CANESM5_r1p2'\n",
    "        else:\n",
    "            m2 = m1\n",
    "    \n",
    "        \n",
    "        length = len(G_ds.sel(model = m2, pulse_type = t).dropna(dim = 's')['s'])\n",
    "        dif_1pct[m] = dif_1pct[m].sel(year = slice(0,length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m1 in ['UKESM1_r1', 'UKESM1_r2', 'UKESM1_r3', 'UKESM1_r4', 'NORESM2',\n",
    "       'GFDL', 'MIROC', 'CANESM5_r1p2', 'CANESM5_r2p2', 'ACCESS', 'CANESM5_r3p2']:\n",
    "    \n",
    "    for t in ['pulse','cdr']:\n",
    "        if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "            m2 = 'UKESM1_r1'\n",
    "        elif m1 == 'CANESM5_r1p2' or m1 == 'CANESM5_r2p2' or m1 == 'CANESM5_r3p2' or m1 == 'CANESM5_r4p2' or m1 == 'CANESM5_r5p2':\n",
    "             m2 = 'CANESM5_r1p2'\n",
    "        else:\n",
    "            m2 = m1    \n",
    "        \n",
    "        length = len(G_ds.sel(model = m2, pulse_type = t).dropna(dim = 's')['s'])\n",
    "        dif_1000gtc[m] = dif_1000gtc[m].sel(year = slice(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dif_1pct = xr.concat([dif_1pct[m] for m in dif_1pct.keys()], pd.Index([m for m in dif_1pct.keys()], name='model'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dif_1000gtc = xr.concat([dif_1000gtc[m] for m in dif_1000gtc.keys()], pd.Index([m for m in dif_1000gtc.keys()], name='model'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dif = xr.concat([ds_dif_1000gtc, ds_dif_1pct], pd.Index(['1000gtc','1pct'], name='experiment'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dif = ds_dif.rename({'year':'s'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emissions profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emis_profile_1pct = xr.open_dataset(f'Outputs/1pct_emis_profile_full.nc4')\n",
    "emis_profile_1pct = emis_profile_1pct.rename({'__xarray_dataarray_variable__':'emis'})\n",
    "\n",
    "emis_profile_1000gtc =  xr.open_dataset(f'Outputs/1pct1000gtc_emis_profile_full.nc4')\n",
    "emis_profile_1000gtc = emis_profile_1000gtc.rename({'__xarray_dataarray_variable__':'emis'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emis_profile = xr.concat([emis_profile_1000gtc, emis_profile_1pct], pd.Index(['1000gtc','1pct'], name='experiment'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our weights for models (grouping UKESM and CANESM realizations)\n",
    "model_weights = {'UKESM1_r1': 0.25, 'UKESM1_r2': 0.25, 'UKESM1_r3': 0.25, 'UKESM1_r4': 0.25, 'NORESM2': 1, 'GFDL': 1,\n",
    "       'MIROC': 1, 'ACCESS': 1,  'CANESM5_r2p2':1/3, 'CANESM5_r1p2':1/3, 'CANESM5_r3p2':1/3}\n",
    "model_weights = xr.DataArray(\n",
    "    data=list(model_weights.values()),\n",
    "    dims=[\"model\"],\n",
    "    coords=dict(\n",
    "        model=([\"model\"], list(model_weights.keys()))\n",
    "    ),\n",
    "    attrs=dict(\n",
    "        description=\"weights for models\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our weights for models (grouping UKESM and CANESM realizations)\n",
    "onepct_model_weights = {'UKESM1_r1': 0.25, 'UKESM1_r2': 0.25, 'UKESM1_r3': 0.25, 'UKESM1_r4': 0.25, 'NORESM2': 1, 'GFDL': 1,\n",
    "       'MIROC': 1, 'CANESM5_r3p1':1/6, 'ACCESS':1, 'CANESM5_r2p2':1/6, 'CANESM5_r2p1':1/6,\n",
    "       'CANESM5_r1p2':1/6, 'CANESM5_r1p1':1/6, 'CANESM5_r3p2':1/6}\n",
    "onepct_model_weights = xr.DataArray(\n",
    "    data=list(onepct_model_weights.values()),\n",
    "    dims=[\"model\"],\n",
    "    coords=dict(\n",
    "        model=([\"model\"], list(onepct_model_weights.keys()))\n",
    "    ),\n",
    "    attrs=dict(\n",
    "        description=\"weights for models\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_model_weights = {'UKESM1_r1': 1, 'NORESM2': 1, 'GFDL': 1,\n",
    "       'MIROC': 1, 'ACCESS': 1,  'CANESM5_r1p2':1/3, 'CANESM5_r2p2':1/3, 'CANESM5_r3p2':1/3}\n",
    "G_model_weights = xr.DataArray(\n",
    "    data=list(G_model_weights.values()),\n",
    "    dims=[\"model\"],\n",
    "    coords=dict(\n",
    "        model=([\"model\"], list(G_model_weights.keys()))\n",
    "    ),\n",
    "    attrs=dict(\n",
    "        description=\"weights for Green's function\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PiCtrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#combine our picontrol data into one dataset, normalizing the time to year 0\n",
    "pictrl = {}\n",
    "for m in tas_co2_pictrl.keys():    \n",
    "    times = tas_co2_pictrl[m].time.get_index('time')\n",
    "    weights = times.shift(-1, 'MS') - times.shift(1, 'MS')\n",
    "    weights = xr.DataArray(weights, [('time', tas_co2_pictrl[m]['time'].values)]).astype('float')\n",
    "    pictrl[m] =  (tas_co2_pictrl[m] * weights).groupby('time.year').sum('time')/weights.groupby('time.year').sum('time')\n",
    "    pictrl[m]['year'] = pictrl[m]['year'] - pictrl[m]['year'][0] \n",
    "    \n",
    "for m in pictrl.keys():\n",
    "    pictrl[m] = pictrl[m].drop('height')\n",
    "ds_pictrl = xr.concat([pictrl[m] for m in pictrl.keys()], pd.Index([m for m in pictrl.keys()], name='model'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Mean Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "GF = G_ds.weighted(A).mean(dim = ['lat','lon'])\n",
    "\n",
    "conv_mean = {}\n",
    "for exp in ['1000gtc','1pct']:\n",
    "    conv_mean[exp] = {}\n",
    "    for m1 in ['UKESM1_r1','UKESM1_r2', 'UKESM1_r3', 'UKESM1_r4', 'NORESM2', 'ACCESS',\n",
    "       'GFDL', 'MIROC', 'CANESM5_r1p2', 'CANESM5_r2p2', 'CANESM5_r3p2']:\n",
    "        conv_mean[exp][m1] = {}\n",
    "        for t in ['pulse','cdr']:\n",
    "            if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "                m2 = 'UKESM1_r1'\n",
    "            else:\n",
    "                m2 = m1\n",
    "            conv_mean[exp][m1][t] = signal.convolve( np.array(GF.sel(model = m2, pulse_type = t).dropna(dim = 's')), np.array(emis_profile.sel(model = m1, experiment = exp)['emis']),'full')\n",
    "            conv_mean[exp][m1][t] = utils.np_to_xr_mean(conv_mean[exp][m1][t], GF.sel(model = m2, pulse_type = t), emis_profile.sel(model = m1, experiment = exp))\n",
    "            length = len(G_ds.weighted(A).mean(dim = ['lat','lon']).dropna(dim = 's')['s'])\n",
    "            conv_mean[exp][m1][t] = conv_mean[exp][m1][t][:length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataset\n",
    "\n",
    "conv_dict = {}\n",
    "for exp in conv_mean.keys():\n",
    "    conv_dict[exp] = {}\n",
    "    for m in conv_mean[exp].keys():\n",
    "        conv_dict[exp][m] = xr.concat([conv_mean[exp][m][t] for t in conv_mean[exp][m].keys()], pd.Index([t for t in conv_mean[exp][m].keys()], name='pulse_type'), coords='minimal')\n",
    "for exp in conv_mean.keys():\n",
    "    conv_dict[exp] = xr.concat([conv_dict[exp][m] for m in conv_mean[exp].keys()], pd.Index([m for m in conv_mean[exp].keys()], name='model'), coords='minimal')\n",
    "conv_mean_ds = xr.concat([conv_dict[exp] for exp in conv_dict.keys()], pd.Index([exp for exp in conv_dict.keys()], name='experiment'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reindex_df(df, weight_col):\n",
    "    \"\"\"expand the dataframe to prepare for resampling\n",
    "    result is 1 row per count per sample\"\"\"\n",
    "    df = df.reindex(df.index.repeat(df[weight_col]))\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "data = {'mean': conv_mean_ds.sel(experiment = '1000gtc').mean(dim = ['pulse_type']).sel(s = slice(60,80)).mean(dim = ['s']).values,\n",
    "        'model': conv_mean_ds.model.values,\n",
    "        'count': [3, 3, 3, 3, 12, 12, 12, 12, 4, 4, 4]}\n",
    "df_1000gtc_emulator = pd.DataFrame(data)\n",
    "df_1000gtc_emulator = reindex_df(df_1000gtc_emulator, weight_col = 'count')\n",
    "\n",
    "data = {'mean': conv_mean_ds.sel(experiment = '1pct').mean(dim = ['pulse_type']).sel(s = slice(60,80)).mean(dim = ['s']).values,\n",
    "        'model': conv_mean_ds.model.values,\n",
    "        'count': [3, 3, 3, 3, 12, 12, 12, 12, 4, 4, 4]}\n",
    "df_1pct_emulator = pd.DataFrame(data)\n",
    "df_1pct_emulator = reindex_df(df_1pct_emulator, weight_col = 'count')\n",
    "\n",
    "\n",
    "data = {'mean': ds_dif.where(ds_dif['model'].isin(model_weights.model.values), drop = True).sel(experiment = '1pct').sel(s = slice(60,80)).weighted(A).mean(dim = ['s', 'lon','lat'])['tas'].values,\n",
    "        'model': ds_dif.where(ds_dif['model'].isin(model_weights.model.values), drop = True).sel(experiment = '1pct').model.values,\n",
    "        'count': [3, 3, 3, 3, 12, 12, 12, 12, 4, 4, 4]}\n",
    "\n",
    "df_1pct_model = pd.DataFrame(data)\n",
    "df_1pct_model = reindex_df(df_1pct_model, weight_col = 'count')\n",
    "\n",
    "\n",
    "#######ZEC############\n",
    "\n",
    "data = {'mean': (conv_mean_ds.sel(experiment = '1000gtc').where(conv_mean_ds['model'].isin(list(model_run_1pct1000gtc_dict.keys())), drop = True).mean(dim = 'pulse_type').sel(\n",
    "                                                                s = slice(80-10, 80+10)).mean(dim = 's').weighted(A).mean(dim = ['lat','lon']) - \n",
    "                    conv_mean_ds.sel(experiment = '1000gtc').where(conv_mean_ds['model'].isin(list(model_run_1pct1000gtc_dict.keys())), drop = True).mean(dim = 'pulse_type').sel(s = 65).weighted(A).mean(dim = ['lat','lon'])).values,\n",
    "        'model': conv_mean_ds.where(conv_mean_ds['model'].isin(list(model_run_1pct1000gtc_dict.keys())), drop = True).model.values,\n",
    "        'count': [3, 3, 3, 3, 12, 12, 12, 4, 4, 4]}\n",
    "\n",
    "df_zec_emulator_model = pd.DataFrame(data)\n",
    "df_zec_emulator_model = reindex_df(df_zec_emulator_model, weight_col = 'count')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = {'mean': (ds_dif.where(ds_dif['model'].isin(list(model_run_1pct1000gtc_dict.keys())), drop = True).sel(experiment = '1000gtc').sel(\n",
    "                                                                s = slice(80-10, 80+10)).mean(dim = 's').weighted(A).mean(dim = ['lat','lon']) - \n",
    "                    ds_dif.where(ds_dif['model'].isin(list(model_run_1pct1000gtc_dict.keys())), drop = True).sel(experiment = '1000gtc').sel(s = 65).weighted(A).mean(dim = ['lat','lon']))['tas'].values,\n",
    "        \n",
    "        'model': ds_dif.where(ds_dif['model'].isin(list(model_run_1pct1000gtc_dict.keys())), drop = True).sel(experiment = '1000gtc').model.values,\n",
    "        'count': [3, 3, 3, 3, 12, 12, 12, 4, 4, 4]}\n",
    "\n",
    "df_zec_cmip_model = pd.DataFrame(data)\n",
    "df_zec_cmip_model = reindex_df(df_zec_cmip_model, weight_col = 'count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "GF = G_ds\n",
    "\n",
    "conv = {}\n",
    "for exp in ['1000gtc','1pct']:\n",
    "    print(exp)\n",
    "    conv[exp] = {}\n",
    "    if exp == '1000gtc':\n",
    "        model_list = ['UKESM1_r1', 'UKESM1_r2', 'UKESM1_r3', 'UKESM1_r4', 'NORESM2', 'MIROC', 'CANESM5_r1p2', 'CANESM5_r2p2', 'ACCESS', 'CANESM5_r3p2',]\n",
    "    elif exp == '1pct':\n",
    "        model_list = ['UKESM1_r1', 'UKESM1_r2', 'UKESM1_r3', 'UKESM1_r4', 'NORESM2', 'GFDL', 'MIROC', 'CANESM5_r1p2', 'CANESM5_r2p2', 'ACCESS', 'CANESM5_r3p2',]\n",
    "    for m1 in model_list:\n",
    "        conv[exp][m1] = {}\n",
    "        for t in ['pulse','cdr']:\n",
    "            if m1 == 'UKESM1_r1' or m1 == 'UKESM1_r2' or m1 == 'UKESM1_r3' or m1 == 'UKESM1_r4':\n",
    "                m2 = 'UKESM1_r1'\n",
    "            else:\n",
    "                m2 = m1\n",
    "            print(m1, m2)\n",
    "            conv[exp][m1][t] = signal.convolve(np.array(GF.sel(model = m2, pulse_type = t).dropna(dim = 's')), \n",
    "                                               np.array(emis_profile.sel(model = m1, experiment = exp)['emis'])[~np.isnan(np.array(emis_profile.sel(model = m1, experiment = exp)['emis']))][..., None, None],\n",
    "                                               'full')\n",
    "            conv[exp][m1][t] = utils.np_to_xr(conv[exp][m1][t], GF.sel(model = m2, pulse_type = t), emis_profile.sel(model = m1, experiment = exp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataset\n",
    "\n",
    "conv_dict = {}\n",
    "for exp in conv.keys():\n",
    "    conv_dict[exp] = {}\n",
    "    for m in conv[exp].keys():\n",
    "        conv_dict[exp][m] = xr.concat([conv[exp][m][t] for t in conv[exp][m].keys()], pd.Index([t for t in conv[exp][m].keys()], name='pulse_type'), coords='minimal')\n",
    "for exp in conv.keys():\n",
    "    conv_dict[exp] = xr.concat([conv_dict[exp][m] for m in conv[exp].keys()], pd.Index([m for m in conv[exp].keys()], name='model'), coords='minimal')\n",
    "conv_ds = xr.concat([conv_dict[exp] for exp in conv_dict.keys()], pd.Index([exp for exp in conv_dict.keys()], name='experiment'), coords='minimal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_mean_ds.to_netcdf('Outputs/conv_mean_ds.nc4')\n",
    "\n",
    "conv_ds.to_netcdf('Outputs/conv_ds.nc4')\n",
    "\n",
    "emis_profile.to_netcdf('Outputs/emis_profile.nc4')\n",
    "\n",
    "ds_dif.to_netcdf('Outputs/ds_dif.nc4')\n",
    "\n",
    "ds_pictrl.to_netcdf('Outputs/ds_pictrl.nc4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gchp)",
   "language": "python",
   "name": "gchp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
